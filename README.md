### **Comment Toxicity Classification App** ðŸ’¬  
- **Overview:**  
  An advanced deep learning-based app designed to classify text comments into various categories of toxicity, including hate speech, offensive language, and harassment. The app helps in moderating online platforms by identifying harmful content and ensuring safer user interactions.  

- **Key Features:**  
  - Classifies comments into toxicity categories such as **toxic**, **severe toxic**, **obscene**, **threat**, **insult**, and **identity hate**.  
  - Uses a deep learning **LSTM recurrent neural network** model for classification.   
  - Provides an intuitive user interface for inputting and displaying results.  

- **Tech Stack:**  
  - **Backend:** Python, TensorFlow/PyTorch for deep learning model 
  - **Frontend:** Streamlit (for web interface).
  - **Deployment:** Streamlit app 

- **Challenges Solved:**  
  - Effectively handles nuanced language patterns and context for accurate toxicity classification.  
  - Deals with unstructured, informal comment text often seen in social media platforms.  
  - Balances false positives and false negatives to improve model precision and recall.  

- **Future Improvements:**  
  - Enhance model accuracy with domain-specific training (e.g., for specific social media platforms).  
  - Add multi-language support for global content moderation.  
  - Incorporate sentiment analysis to assess the severity of toxic comments.  

- **Impact:**  
  Aims to improve online discourse by providing automated moderation tools, reducing harmful content, and fostering positive environments on digital platforms.  

- **Live Demo:**  
  A **Streamlit** demo via hugging faces for testing the toxicity classification in real-time.

  ![image](https://github.com/user-attachments/assets/e9a9360e-2c0a-4bc7-b7ac-56d0116053cb)

  - **Link** - https://huggingface.co/spaces/ad-2004/comment-toxicity-analyser
